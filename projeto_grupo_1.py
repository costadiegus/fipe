# -*- coding: utf-8 -*-
"""projeto_grupo_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10FAjSYEckDW73Sl3zA3GNEQNzXm0YARJ

# Projeto: Fundamento de Machine Learning

**Professor:** Jorge Chamby-Diaz  
**Turma:** Caixaverso - Especialista em IA  
**Link grupos projeto:** [Planilha de grupos](https://docs.google.com/spreadsheets/d/1ixM0IRVW40Ptf7T4Q2qYt0NJbzcVoKAKWG5Zf5-Q1UQ/edit?usp=sharing)

<center><h3>Projeto Final - Fundamento de Machine Learning<h3></center>

**Descri√ß√£o**  
Este notebook cont√©m a descri√ß√£o do projeto pr√°tico do m√≥dulo: Fundamento de Machine Learning. Neste projeto, os alunos dever√£o aplicar os conhecimentos aprendidos em aula, desde a an√°lise explorat√≥ria at√© a constru√ß√£o de um modelo supervisionado, passando pela escolha do problema, estrutura√ß√£o da base, ajuste de hiperpar√¢metros e an√°lise dos resultados.

**Objetivo**  
Realizar uma an√°lise explorat√≥ria de dados e construir um modelo de Machine Learning supervisionado (classifica√ß√£o ou regress√£o) para resolver um problema real baseado em dados.

Sua an√°lise deve conter um *storytelling*: uma hist√≥ria guiada por dados, gr√°ficos, imagens e medidas estat√≠sticas, que conduza o leitor desde o problema at√© a solu√ß√£o proposta. O projeto deve abordar um problema relevante encontrado na base escolhida, justificar por que ele √© interessante e, a partir disso, construir um modelo preditivo com base em t√©cnicas supervisionadas.  

Voc√™ est√° livre para utilizar quantas bases considerar necess√°rio e filtrar as informa√ß√µes mais relevantes para sua hist√≥ria.

**Dados**  
Esta √© uma lista de fontes que voc√™s podem utilizar. Outras fontes tamb√©m s√£o permitidas, desde que haja uma valida√ß√£o pr√©via com o professor.

#### Fontes de dados sugeridas:
- [Covid19br](https://github.com/wcota/covid19br/)
- [Ag√™ncia Nacional de Petr√≥leo e G√°s](https://bit.ly/3hf8rbZ)
- [DataSUS (via FTP)](ftp.datasus.gov.br)
- [Dados.gov.br](https://bit.ly/3fPA1MO)
- [Kaggle](https://www.kaggle.com/)

> *Obs: Para acessar o FTP do DataSUS, utilize um cliente como o Filezilla.*

---

## Organiza√ß√£o e entreg√°veis

- O projeto pode ser feito em grupo de at√© 05 participantes.  
- O projeto completo (notebook, c√≥digo-fonte, links para fontes, bases e demais artefatos) deve ser:
  - Publicado no GitHub;
  - Enviado por e-mail (jchambyd@gmail.com), com nome dos participantes e link do reposit√≥rio no GitHub.  
  - Assunto do e-mail: **Projeto Caixaverso - Fundamento de ML**

---

## Entreg√°veis esperados

- An√°lise explorat√≥ria de dados (EDA);
- Identifica√ß√£o de um problema relevante no(s) dataset(s) escolhido(s);
- Formula√ß√£o do problema como uma tarefa de **classifica√ß√£o ou regress√£o**;
- Constru√ß√£o de um ou mais modelos de Machine Learning supervisionado;
- Avalia√ß√£o comparativa dos modelos com **m√©tricas adequadas**;
- Realiza√ß√£o de **ajuste de hiperpar√¢metros**;
- Justificativa clara da escolha final do modelo;
- Visualiza√ß√µes e interpreta√ß√µes dos resultados.

---

## Crit√©rios de Avalia√ß√£o

A avalia√ß√£o ser√° feita com base nos artefatos entregues e na apresenta√ß√£o final do grupo.

### Apresenta√ß√£o
- Storytelling claro e objetivo;
- Identifica√ß√£o de padr√µes e insights na base de dados;
- Clareza na defini√ß√£o do problema e proposta de solu√ß√£o;
- Conclus√µes e recomenda√ß√µes.

### T√©cnicos
- EDA bem estruturada, incluindo:
  - Descri√ß√£o das vari√°veis;
  - Dados faltantes;
  - Tipos de dados e limpeza da base;
- An√°lises univariadas e multivariadas;
  - Medidas estat√≠sticas;
  - Gr√°ficos e visualiza√ß√µes;
- Formula√ß√£o e modelagem:
  - Defini√ß√£o do problema como tarefa de ML (classifica√ß√£o ou regress√£o);
  - Treinamento e avalia√ß√£o de modelos;
  - Escolha da(s) m√©trica(s) de avalia√ß√£o;
  - Ajuste de hiperpar√¢metros;
  - Reprodutibilidade do c√≥digo.

### Comunica√ß√£o
- Clareza na explica√ß√£o do problema, da abordagem adotada e dos resultados obtidos;
- Boa organiza√ß√£o do notebook e do reposit√≥rio;
- Visualiza√ß√µes compreens√≠veis e informativas.

---

## Deadline
**Apresenta√ß√£o final:** 29/07/2025  
**Tempo estimado por grupo:** 15 ~ 20 minutos  
**Entrega via e-mail e GitHub:** at√© a v√©spera da apresenta√ß√£o

---

Boa sorte e m√£os √† obra! üöÄ

# Trabalho Final - Grupo 1

## Informa√ß√µes Gerais

**Integrantes**
- Alexandre Ventrice (alexandre.ventrice@gmail.com)
- Diego Gustavo (costadiegus@gmail.com)
- F√°bio Alves Braga (fabiobragasp@gmail.com)
- Paulo Donizetti (paulinhodgf@gmail.com)
- R√¥mulo Fuzo (romulo.fuzo@gmail.com)
- Waldir Jos√© Ferreira Jr (ferreirajrfarma@gmail.com)

Fonte: https://docs.google.com/spreadsheets/d/1ixM0IRVW40Ptf7T4Q2qYt0NJbzcVoKAKWG5Zf5-Q1UQ/edit?gid=0#gid=0

## Importa√ß√µes
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.preprocessing import LabelEncoder

import warnings
warnings.filterwarnings("ignore")

"""## Carga de Dados"""

# CARGA DO DATASET DIRETO DO SITE DO KAGGLE
import os
from pathlib import Path

# 1. Autentica√ß√£o: verifica se kaggle.json j√° existe
kaggle_path = Path("~/.kaggle/kaggle.json").expanduser()
if not kaggle_path.exists():
    from google.colab import files
    print("kaggle.json n√£o encontrado. Fa√ßa o upload:")
    uploaded = files.upload()
    os.makedirs(kaggle_path.parent, exist_ok=True)
    (kaggle_path).write_bytes(uploaded["kaggle.json"])
    kaggle_path.chmod(0o600)
else:
    print("kaggle.json j√° est√° configurado.")

# 2. Instalar CLI do Kaggle (caso ainda n√£o esteja)
!pip install -q kaggle

# 3. Baixar e extrair o dataset correto
!kaggle datasets download -d vagnerbessa/average-car-prices-bazil
!unzip -o average-car-prices-bazil.zip -d dataset/

# 4. Verificar os arquivos baixados
print("Arquivos na pasta 'dataset':", os.listdir("dataset"))

# Carregando o dataset
csv_path = 'dataset/fipe_cars.csv'
try:
    df = pd.read_csv(csv_path, encoding='latin1')
except FileNotFoundError:
    print(f"Arquivo '{csv_path}' n√£o encontrado.")
    exit()

"""## An√°lise Explorat√≥ria de Dados"""

df.shape

df.head()

df.info()

df.describe()

import seaborn as sns
import matplotlib.pyplot as plt

# Calcula a correla√ß√£o num√©rica
cor = df.corr(numeric_only=True)

# Reordena as colunas com base na correla√ß√£o com 'avg_price_brl'
target_corr = cor['avg_price_brl'].abs().sort_values(ascending=False).index
cor_sorted = cor.loc[target_corr, target_corr]

# Heatmap centralizado na 'avg_price_brl'
sns.heatmap(cor_sorted, cmap='coolwarm', annot=False, center=0)
plt.title("Correla√ß√£o entre vari√°veis ordenadas pela avg_price_brl")
plt.show()

# Cria DataFrame para usar 'hue'
target_corr = cor['avg_price_brl'].drop('avg_price_brl').sort_values(key=abs, ascending=False)
corr_df = target_corr.reset_index()
corr_df.columns = ['feature', 'correlation']

plt.figure(figsize=(8, 6))
sns.barplot(
    data=corr_df,
    x='correlation',
    y='feature',
    hue='correlation',
    palette='coolwarm',
    dodge=False,
    legend=False
)
plt.title("Correla√ß√£o com a vari√°vel alvo: avg_price_brl")
plt.xlabel("Coeficiente de Correla√ß√£o")
plt.ylabel("Vari√°veis")
plt.axvline(0, color='gray', linestyle='--')
plt.tight_layout()
plt.show()

sns.pairplot(df)

"""## Tratamento dos dados"""

# --- Verifica√ß√£o e Remo√ß√£o de Linhas Duplicadas ---
print(f"N√∫mero de linhas antes de remover duplicatas: {len(df)}")

num_duplicates = df.duplicated().sum()
if num_duplicates > 0:
    print(f"Encontradas e removidas {num_duplicates} linhas duplicadas.")
    df.drop_duplicates(inplace=True)
else:
    print("Nenhuma linha duplicada encontrada.")

print(f"N√∫mero de linhas ap√≥s remover duplicatas: {len(df)}")
print("-" * 30)

# Fuel e Gear
df_processed = df.copy()
df_processed = pd.get_dummies(df_processed, columns=['fuel', 'gear'], prefix=['fuel', 'gear'])

# Brand
le_brand = LabelEncoder()
df_processed['brand_encoded'] = le_brand.fit_transform(df_processed['brand'])
df_processed = df_processed.drop(['brand'], axis=1)

# Model
le_model = LabelEncoder()
df_processed['model_encoded'] = le_model.fit_transform(df_processed['model'])
df_processed = df_processed.drop(['model'], axis=1)

# Retirar colunas irrelevantes pro modelo
df_processed = df_processed.drop(['fipe_code', 'authentication', 'month_of_reference'], axis=1)

# Deletar colunas nulas caso existam
df_processed = df_processed.dropna()

df_processed.columns

display(df_processed)

"""## Modelagem"""

# --- Prepara√ß√£o dos Dados para o Modelo ---
X = df_processed.drop('avg_price_brl', axis=1)
y = df_processed['avg_price_brl']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Escalamos os dados para otimizar a Regress√£o Linear
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Treinamento e Avalia√ß√£o do Modelo usando LinearRegression

l_regressor = LinearRegression()
l_regressor.fit(X_train_scaled, y_train)
y_pred_l_regressor = l_regressor.predict(X_test_scaled)

# Treinamento e Avalia√ß√£o do Modelo usando DecisionTreeRegressor
dt_regressor = DecisionTreeRegressor(random_state=42)
dt_regressor.fit(X_train, y_train)
y_pred_dt_regressor = dt_regressor.predict(X_test)

# Treinamento e Avalia√ß√£o do Modelo usando RandomForestRegressor
rf_regressor = RandomForestRegressor(random_state=42)
rf_regressor.fit(X_train, y_train)
y_pred_rf_regressor = rf_regressor.predict(X_test)

"""## Avalia√ß√£o

### LinearRegression
"""

r2 = r2_score(y_test, y_pred_l_regressor)
mae = mean_absolute_error(y_test, y_pred_l_regressor)
mse = mean_squared_error(y_test, y_pred_l_regressor)
rmse = np.sqrt(mse)

print("\nResultados do Modelo Ap√≥s Remo√ß√£o de Duplicatas:")
print(f"R¬≤: {r2:.3f}")
print(f"MAE: R$ {mae:,.2f}")
print(f"MSE: R$¬≤ {mse:,.2f}")
print(f"RMSE: R$ {rmse:,.2f}")

# --- Visualiza√ß√£o ---
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred_l_regressor, alpha=0.5)
plt.title('Compara√ß√£o Valor Real vs. Previsto (Dados Limpos)')
plt.xlabel('Valor Real (R$)')
plt.ylabel('Valor Previsto (R$)')
plt.grid(True)
max_val = max(y_test.max(), y_pred_l_regressor.max())
plt.plot([0, max_val], [0, max_val], 'r--')
plt.savefig('linear_prediction_no_duplicates.png')
plt.show()

# --- Criar um exemplo de carro para fazer a previs√£o ---
# Voc√™ pode alterar os valores neste dicion√°rio para testar outros carros
car_example_data = {
    'year_of_reference': [2023], # Ano de refer√™ncia da tabela FIPE
    'brand': ['GM - Chevrolet'],
    'model': ['ONIX HATCH 1.0 12V Flex 5p Mec.'],
    'fuel': ['Gasoline'],
    'gear': ['manual'],
    'engine_size': [1.0],
    'year_model': [2019] # Ano de fabrica√ß√£o do carro
}

car_df = pd.DataFrame(car_example_data)

print("Dados do carro para previs√£o:")
print(car_df)
print("-" * 30)

# --- Aplicar as mesmas transforma√ß√µes dos dados de treino ---
# √â CRUCIAL usar os encoders j√° treinados (.transform) e n√£o treinar de novo (.fit_transform)
car_df['brand_encoded'] = le_brand.transform(car_df['brand'])
car_df['model_encoded'] = le_model.transform(car_df['model'])

# Aplicar One-Hot Encoding
car_df = pd.get_dummies(car_df, columns=['fuel', 'gear'], prefix=['fuel', 'gear'])
car_df = car_df.drop(['brand', 'model'], axis=1)

# Alinhar as colunas do nosso exemplo com as colunas do modelo
# Isso garante que teremos todas as colunas do one-hot encoding, preenchendo com 0 as que n√£o existem no exemplo
final_car_df = car_df.reindex(columns=X.columns, fill_value=0)


# --- Fazer a previs√£o ---
predicted_price = l_regressor.predict(final_car_df)

print(f"Pre√ßo PREVISTO para o carro: R$ {predicted_price[0]:,.2f}")

"""#### DecisionTreeRegressor"""

r2 = r2_score(y_test, y_pred_dt_regressor)
mae = mean_absolute_error(y_test, y_pred_dt_regressor)
mse = mean_squared_error(y_test, y_pred_dt_regressor)
rmse = np.sqrt(mse)

print("\nResultados do Modelo Ap√≥s Remo√ß√£o de Duplicatas:")
print(f"R¬≤: {r2:.3f}")
print(f"MAE: R$ {mae:,.2f}")
print(f"MSE: R$¬≤ {mse:,.2f}")
print(f"RMSE: R$ {rmse:,.2f}")

# --- Visualiza√ß√£o ---
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred_dt_regressor, alpha=0.5)
plt.title('Compara√ß√£o Valor Real vs. Previsto (Dados Limpos)')
plt.xlabel('Valor Real (R$)')
plt.ylabel('Valor Previsto (R$)')
plt.grid(True)
max_val = max(y_test.max(), y_pred_dt_regressor.max())
plt.plot([0, max_val], [0, max_val], 'r--')
plt.savefig('decision_tree_prediction_no_duplicates.png')
plt.show()

# --- Criar um exemplo de carro para fazer a previs√£o ---
# Voc√™ pode alterar os valores neste dicion√°rio para testar outros carros
car_example_data = {
    'year_of_reference': [2023], # Ano de refer√™ncia da tabela FIPE
    'brand': ['GM - Chevrolet'],
    'model': ['ONIX HATCH 1.0 12V Flex 5p Mec.'],
    'fuel': ['Gasoline'],
    'gear': ['manual'],
    'engine_size': [1.0],
    'year_model': [2019] # Ano de fabrica√ß√£o do carro
}

car_df = pd.DataFrame(car_example_data)

print("Dados do carro para previs√£o:")
print(car_df)
print("-" * 30)

# --- Aplicar as mesmas transforma√ß√µes dos dados de treino ---
# √â CRUCIAL usar os encoders j√° treinados (.transform) e n√£o treinar de novo (.fit_transform)
car_df['brand_encoded'] = le_brand.transform(car_df['brand'])
car_df['model_encoded'] = le_model.transform(car_df['model'])

# Aplicar One-Hot Encoding
car_df = pd.get_dummies(car_df, columns=['fuel', 'gear'], prefix=['fuel', 'gear'])
car_df = car_df.drop(['brand', 'model'], axis=1)

# Alinhar as colunas do nosso exemplo com as colunas do modelo
# Isso garante que teremos todas as colunas do one-hot encoding, preenchendo com 0 as que n√£o existem no exemplo
final_car_df = car_df.reindex(columns=X.columns, fill_value=0)


# --- Fazer a previs√£o ---
predicted_price = dt_regressor.predict(final_car_df)

print(f"Pre√ßo PREVISTO para o carro: R$ {predicted_price[0]:,.2f}")

"""#### RandomForestRegressor"""

r2 = r2_score(y_test, y_pred_rf_regressor)
mae = mean_absolute_error(y_test, y_pred_rf_regressor)
mse = mean_squared_error(y_test, y_pred_rf_regressor)
rmse = np.sqrt(mse)

print("\nResultados do Modelo Ap√≥s Remo√ß√£o de Duplicatas:")
print(f"R¬≤: {r2:.3f}")
print(f"MAE: R$ {mae:,.2f}")
print(f"MSE: R$¬≤ {mse:,.2f}")
print(f"RMSE: R$ {rmse:,.2f}")

# --- Visualiza√ß√£o ---
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred_rf_regressor, alpha=0.5)
plt.title('Compara√ß√£o Valor Real vs. Previsto (Dados Limpos)')
plt.xlabel('Valor Real (R$)')
plt.ylabel('Valor Previsto (R$)')
plt.grid(True)
max_val = max(y_test.max(), y_pred_rf_regressor.max())
plt.plot([0, max_val], [0, max_val], 'r--')
plt.savefig('random_forest_prediction_no_duplicates.png')
plt.show()

# --- Criar um exemplo de carro para fazer a previs√£o ---
# Voc√™ pode alterar os valores neste dicion√°rio para testar outros carros
car_example_data = {
    'year_of_reference': [2023], # Ano de refer√™ncia da tabela FIPE
    'brand': ['GM - Chevrolet'],
    'model': ['ONIX HATCH 1.0 12V Flex 5p Mec.'],
    'fuel': ['Gasoline'],
    'gear': ['manual'],
    'engine_size': [1.0],
    'year_model': [2019] # Ano de fabrica√ß√£o do carro
}

car_df = pd.DataFrame(car_example_data)

print("Dados do carro para previs√£o:")
print(car_df)
print("-" * 30)

# --- Aplicar as mesmas transforma√ß√µes dos dados de treino ---
# √â CRUCIAL usar os encoders j√° treinados (.transform) e n√£o treinar de novo (.fit_transform)
car_df['brand_encoded'] = le_brand.transform(car_df['brand'])
car_df['model_encoded'] = le_model.transform(car_df['model'])

# Aplicar One-Hot Encoding
car_df = pd.get_dummies(car_df, columns=['fuel', 'gear'], prefix=['fuel', 'gear'])
car_df = car_df.drop(['brand', 'model'], axis=1)

# Alinhar as colunas do nosso exemplo com as colunas do modelo
# Isso garante que teremos todas as colunas do one-hot encoding, preenchendo com 0 as que n√£o existem no exemplo
final_car_df = car_df.reindex(columns=X.columns, fill_value=0)


# --- Fazer a previs√£o ---
predicted_price = rf_regressor.predict(final_car_df)

print(f"Pre√ßo PREVISTO para o carro: R$ {predicted_price[0]:,.2f}")

"""### Ajuste de Hiperpar√¢metros"""

# Importa√ß√µes
!pip install scikit-optimize
from sklearn.model_selection import GridSearchCV
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint, uniform
from skopt import BayesSearchCV
from skopt.space import Real, Integer, Categorical
from sklearn.tree import DecisionTreeRegressor

param_DecisionTree = {
    'max_features': ['sqrt', 'log2'], # N√∫mero de recursos a serem considerados para cada divis√£o
    'criterion': ['squared_error', 'friedman_mse'], # Fun√ß√£o de avalia√ß√£o da qualidade da divis√£o
    'splitter': ['best', 'random'] # Estrat√©gia para escolher as divis√µes
}
param_RandomForest = {
    'n_estimators': [20, 25, 30],            # N√∫mero de √°rvores na floresta
    'max_features': ['sqrt', 'log2'] # N√∫mero de recursos a serem considerados ao procurar a melhor divis√£o
}
reg_DecisionTree = DecisionTreeRegressor(random_state=42)
reg_RandomForest = RandomForestRegressor(random_state=42)

"""#### GridSearchCV"""

# Verificar melhores HIPERPARAMETROS - GridSearchCV - DecisionTree
grid_search = GridSearchCV(reg_DecisionTree, param_DecisionTree, cv=5, verbose=3, scoring='neg_mean_absolute_error')
grid_search.fit(X, y)
print("Melhores par√¢metros:", grid_search.best_params_)
print("Melhor MSE negativo:", abs(grid_search.best_score_))

"""Melhores par√¢metros: {'criterion': 'friedman_mse', 'max_features': 'sqrt', 'splitter': 'random'}
Melhor MSE negativo: 6252.434445084424
"""

# Verificar melhores HIPERPARAMETROS - GridSearchCV - RandomForest
grid_search = GridSearchCV(reg_RandomForest, param_RandomForest, cv=5, verbose=3, scoring='neg_mean_absolute_error')
grid_search.fit(X, y)
print("Melhores par√¢metros:", grid_search.best_params_)
print("Melhor MSE negativo:", abs(grid_search.best_score_))

"""Melhores par√¢metros: {'max_features': 'sqrt', 'n_estimators': 30}
Melhor MSE negativo: 6201.352139317452

#### RandomizedSearchCV
"""

# Verificar melhores HIPERPARAMETROS - RandomizedSearchCV - DecisionTree
random_search = RandomizedSearchCV(
    estimator=reg_DecisionTree,
    param_distributions=param_DecisionTree,
    n_iter=100,  # voc√™ pode ajustar para controlar tempo vs. cobertura
    scoring='neg_mean_squared_error',
    cv=5,
    random_state=42,
    n_jobs=-1,
    verbose=3
)

random_search.fit(X_train, y_train)

print("Melhores par√¢metros:", random_search.best_params_)
print("Melhor MSE negativo:", random_search.best_score_)

"""Melhores par√¢metros: {'splitter': 'best', 'max_features': 'sqrt', 'criterion': 'friedman_mse'}
Melhor MSE negativo: -488511387.64851725
"""

# Verificar melhores HIPERPARAMETROS - RandomizedSearchCV - RandomForest
random_search = RandomizedSearchCV(
    estimator=reg_RandomForest,
    param_distributions=param_RandomForest,
    n_iter=50,  # voc√™ pode ajustar para controlar tempo vs. cobertura
    scoring='neg_mean_squared_error',
    cv=5,
    random_state=42,
    n_jobs=-1,
    verbose=3
)

random_search.fit(X_train, y_train)

print("Melhores par√¢metros:", random_search.best_params_)
print("Melhor MSE negativo:", random_search.best_score_)

"""Melhores par√¢metros: {'n_estimators': 30, 'max_features': 'sqrt'}
Melhor MSE negativo: -361890718.26409256

#### BayesSearchCV
"""

# Verificar melhores HIPERPARAMETROS - BayesSearchCV - DecisionTree
opt = BayesSearchCV(
    estimator=reg_DecisionTree,
    search_spaces=param_DecisionTree,
    scoring='neg_mean_squared_error',
    n_iter=50,  # pode ajustar (mais = melhor mas mais lento)
    cv=5,
    n_jobs=-1,
    verbose=3,
    random_state=42
)

opt.fit(X_train, y_train)

print("Melhores par√¢metros:", opt.best_params_)
print("Melhor MSE negativo:", opt.best_score_)

"""Melhores par√¢metros: OrderedDict([('criterion', 'friedman_mse'), ('max_features', 'log2'), ('splitter', 'best')])
Melhor MSE negativo: -488511387.64851725
"""

# Verificar melhores HIPERPARAMETROS - BayesSearchCV - RandomForest
opt = BayesSearchCV(
    estimator=reg_RandomForest,
    search_spaces=param_RandomForest,
    scoring='neg_mean_squared_error',
    n_iter=50,  # pode ajustar (mais = melhor mas mais lento)
    cv=5,
    n_jobs=-1,
    verbose=3,
    random_state=42
)

opt.fit(X_train, y_train)

print("Melhores par√¢metros:", opt.best_params_)
print("Melhor MSE negativo:", opt.best_score_)

"""Melhores par√¢metros: OrderedDict([('max_features', 'sqrt'), ('n_estimators', 30)])
Melhor MSE negativo: -361890718.26409256

### Valida√ß√£o Cruzada
"""

from sklearn.model_selection import cross_validate, KFold
from sklearn.metrics import make_scorer

from sklearn.linear_model import ElasticNet

# Fun√ß√£o reutilizada para valida√ß√£o cruzada
def plot_cv(estimator, X, y, n_splits, scoring):
    '''
    scoring: string relativa √†s m√©tricas
    '''

    kf5 = KFold(n_splits=n_splits, shuffle=True, random_state=42)

    result_cv = cross_validate(estimator=estimator, X=X, y=y,
                               cv=kf5, scoring=scoring,
                               return_train_score=True)

    # ============================

    df_result_cv = pd.DataFrame(result_cv)
    df_result_cv = df_result_cv.abs()

    display(df_result_cv[["train_score", "test_score"]].describe())

    print("Diferen√ßa entre treino e teste")
    display((df_result_cv["train_score"] - df_result_cv["test_score"]).mean())

    # ============================

    print("\nDistribui√ß√£o de m√©tricas de treino:")
    sns.histplot(data=df_result_cv, x="train_score", kde=True)
    plt.show()

    print("\nDistribui√ß√£o de m√©tricas de teste:")
    sns.histplot(data=df_result_cv, x="test_score", kde=True)
    plt.show()

    print("\nAs duas juntas (compare a vari√¢ncia!):")
    sns.histplot(data=df_result_cv, x="train_score", kde=True)
    sns.histplot(data=df_result_cv, x="test_score", color="orange", kde=True)
    plt.show()

# Utilizar o Cross Validation para avaliar o desvio m√©dio do modelo
en = DecisionTreeRegressor(max_depth= 20, min_samples_leaf= 1) # J√° com o resultado do GridSearchCV

plot_cv(en, X, y, n_splits=30, scoring="neg_mean_absolute_error")

# Utilizar o Cross Validation para avaliar o desvio m√©dio do modelo
en = RandomForestRegressor(max_features='log2', n_estimators=25) # J√° com o resultado do GridSearchCV

plot_cv(en, X, y, n_splits=30, scoring="neg_mean_absolute_error")

"""**Conclus√µes**

O train_score est√£o muito pr√≥ximos os valores, ou seja, n√£o temos overfiting.
Se a diferen√ßa entre treino e teste for pequena (como √©), ent√£o o modelo est√° est√°vel, mas possivelmente subajustado (underfitting).
O desvio padr√£o dos scores entre as dobras (~500‚Äì600) mostra varia√ß√£o moderada, o que √© aceit√°vel.
O modelo parece consistente entre os diferentes subconjuntos de dados
"""